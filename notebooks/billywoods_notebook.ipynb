{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njYRRFGRVTwm",
    "outputId": "a92a5735-41b7-45d9-a15d-699bd5ade624"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIGX2fwYeYFY"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy\n",
    "    !pip install --no-deps git+https://github.com/mmathew23/unsloth-zoo.git@t4mixed\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLe5bNVR2xnm",
    "outputId": "9c5e2956-baa6-4e34-9b82-a22f5aaaffeb"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnTf0bQceYFa",
    "outputId": "bfc07514-9d5e-41cd-e14d-b7cc9669d05f"
   },
   "outputs": [],
   "source": [
    "%env UNSLOTH_RETURN_LOGITS=1 # Run this to disable CCE since it is not supported for CPT\n",
    "\n",
    "%env TRANSFORMERS_VERBOSITY=info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "f5f9990c-fb0a-424c-f809-8428ff6181c0"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 512\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "374e6495-3122-45c2-d73c-cd8950ab7151"
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "\n",
    "                      \"embed_tokens\", \"lm_head\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzo_jo_V3k5C",
    "outputId": "10b6cb2c-a0d6-4644-91ca-bb5a3b98f281"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "folder_path = \"path\"\n",
    "\n",
    "\n",
    "sentences = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        blob = TextBlob(text)\n",
    "        sentences.extend(blob.sentences)\n",
    "\n",
    "\n",
    "print(f\"Collected {len(sentences)} total sentences.\")\n",
    "print(sentences[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "3L6SrvTC34O1",
    "outputId": "bb1b4449-3208-4418-b3dc-577f38ec698e"
   },
   "outputs": [],
   "source": [
    "\n",
    "chunks = []\n",
    "for s in range(len(sentences) - 3):\n",
    "  chunks.append(\" \".join([str(sent) for sent in sentences[s:s+3]]))\n",
    "\n",
    "chunks[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ItWyTNXi4HrM",
    "outputId": "5a8c2dd2-f488-4708-b025-71fd6364b8e8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(chunks, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j93TpOSG4MtL",
    "outputId": "b1e3ddf3-e6a5-4c8d-9ae2-e4282cbdded0"
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset[900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ENCwwLaWjud"
   },
   "source": [
    "Print out 5 stories from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMv7nqxz6fta",
    "outputId": "eb763ec6-9c96-48e7-bcba-d7b267671016"
   },
   "outputs": [],
   "source": [
    "for row in dataset[:5][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsby_T-h4Vbw"
   },
   "source": [
    "Tokenize it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ab32c6c7f9d943b9844d60208635e45f",
      "443422488f61440cb49ba577bb70610d",
      "5e239d855dbd493ebe870458f09c1ed8",
      "4c33e317d47d47c481d1588c144ff5e0",
      "ca9e5fdf495647e6b530b8fbcfd7f221",
      "4fb18337e5e44ba58c14a8617d16b2b4",
      "8a225190adcf4e7a8200a4bcb4b77e17",
      "03e580e0f3f54bcc8cc508362721ea45",
      "5daf77ee38bb45f3a01576da16b173fb",
      "64041b5f6ab0490a8e9dd2de31a4c692",
      "6d899ec27f384ca3b5926e8b39399ba6"
     ]
    },
    "id": "Y8EVdG2H4XhR",
    "outputId": "3cbd70d4-56eb-45ac-bf4c-58ce402c7bfa"
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    return { \"text\" : [example + EOS_TOKEN for example in examples[\"text\"]] }\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "37a2edc93ee740028b8ad56e661a70c6",
      "cced4d2c44804f9e92a982ff588c659b",
      "cdd265391164478d8afa008982a3e457",
      "e97e203ef794474084d2e8b641eae1a1",
      "91be914649ac4df58cfc3225600305dc",
      "a230f75a98da44338fd47e3880468446",
      "ec6498b341894d71a1f3591edb725482",
      "7ef3d70a60fd4ed0a7e724f8db88541f",
      "279b5cbd738549b191d59d8859e42e89",
      "053cb156328c45499c9ee201d2e5e13b",
      "ad72f83731af4fe283b298a8ff345f7f"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "53d13543-ca6d-419a-b8bd-1a5270745392"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 3,\n",
    "\n",
    "        learning_rate = 2e-5,\n",
    "        embedding_learning_rate = 5e-6,\n",
    "\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "a0981bb3-842c-4187-dddc-7b313fe416b0"
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHm11vaQRt1U",
    "outputId": "7a49ce39-a2ff-4cb1-adc5-41daab7c9f00"
   },
   "outputs": [],
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "import textwrap\n",
    "max_print_width = 50\n",
    "\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"Foreman we rush\"\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "generation_kwargs = dict(\n",
    "    inputs,\n",
    "    max_new_tokens = 256,\n",
    "    use_cache = True,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_k = 50,\n",
    ")\n",
    "\n",
    "outputs = model.generate(**generation_kwargs)\n",
    "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "for text in generated_text:\n",
    "    wrapped_text = textwrap.fill(text, width=max_print_width)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtLG3j8GLX8Y"
   },
   "source": [
    "## Save the model as a GGUF\n",
    "\n",
    "hopefully..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5ee5a79168694ef2be6a564b727e56c3",
      "c0541ad82f9f42e08b544747471c7638",
      "d3e2fabda22540828c9a90df3703f5bf",
      "18a7e6c25b404e4a8cbe9512a6f5ad02",
      "2e3ae34d76fa4522982f1d5559c5e50d",
      "60318d7e818747b785da2beebd48b4f0",
      "5bac52c1d1124fb896b56a895a1e68c2",
      "4f8c6a5c33b449ccbcd873c6adf8bd1b",
      "ab968268ed2a4e739f4a270e34a3728d",
      "6587c99f1817462397522ab534db8526",
      "4c4a3756c40f4545ab142c3916fa29fa",
      "18b0ecca92c74007812b53831f66c76f",
      "2b53493e14114654861f93fa6b7901f0",
      "13fa5b0039d6468aa1a3bf77854d30ff",
      "3c8dd8534bd3499cb6d929efc9928913",
      "959590472b594a939491d2158dd90c73",
      "d05aefdf59d447ce8f25a7642f227f12",
      "e1892e3646084ed4b68e42d6f6c00819",
      "a11005953a424e8cbeb3a3db143320d8",
      "7988c831bf53441b9abfdf4079048008",
      "79099834cfd34f3e9eb4ec1f1a312ee0",
      "9201e0a3399448d4a6e346cf814efe74",
      "8e5f4fbaeaad4d93b3cf1fac0dec6094",
      "8b3d149a23124caab30e6d5803c09c60",
      "b6f95250d7ff4623ad6f756f8f24d750",
      "debc2cec651a4bf7a31247ab8a4a91a5",
      "9a3efcc4c5cb4cc986ee4af5dc7350f2",
      "cdc7cb198c554449a4341623ccc66ff0",
      "089cc993f43444e2968cb65cdfa61e7b",
      "9cb7c38b30df4bfcae10e48c4031a042",
      "1b60c557be6845dab0a5e895c717dd81",
      "f2f1c0b56b084d39988b8ade7af79b49",
      "120370679b264df184c3f671c30b9d69"
     ]
    },
    "id": "5d9bf0d5",
    "outputId": "ead8099b-aac4-49f1-f6fc-808dbe3c40e0"
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"path\", token = \"token\")\n",
    "tokenizer.push_to_hub(\"path\", token = \"token\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
